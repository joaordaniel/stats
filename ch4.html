<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>ch4.utf8.md</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/paper.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 64px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 69px;
  margin-top: -69px;
}

.section h2 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h3 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h4 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h5 {
  padding-top: 69px;
  margin-top: -69px;
}
.section h6 {
  padding-top: 69px;
  margin-top: -69px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="index.html">Welcome</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="ch1.html">1. Mixed Models – why?</a>
    </li>
    <li>
      <a href="ch2.html">2. Tidying Data</a>
    </li>
    <li>
      <a href="ch3.html">3. The Basic Two-Level Model</a>
    </li>
    <li>
      <a href="ch4.html">4. The Random Intercept Random Slope Model</a>
    </li>
    <li>
      <a href="ch5.html">5. Interaction Effects and Centering</a>
    </li>
    <li>
      <a href="ch6.html">6. Three Level Models</a>
    </li>
    <li>
      <a href="ch7.html">7. Longitudinal Data / Repeated Measures</a>
    </li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">




</div>


<div id="the-random-intercept-random-slope-model" class="section level1">
<h1>4. The Random Intercept Random Slope Model</h1>
<p>So far we have assumed that the effect of the <em>illiterate</em> covariate is the same across all parishes (remember all those parallel lines in <strong>figure 3.3.2</strong>?). What happens if we let the slopes vary? That is, if we let the effects of the number of illiterate residents vary from group to group?</p>
<p>Let’s go create <strong>model 4</strong>. Just follow the same steps you took for model 3. Go back to <strong>figure 3.2.1</strong> and to the instructions on the beginning of <strong>section 3.3</strong> if you feel lost. The only difference is that in the <strong>Linear Mixed Models: Random Effects dialog box</strong> you have to add <em>illiterate_within</em> to the <strong>Model box</strong> (<strong>figure 4.1</strong>). In the <strong>Linear Mixed Models: Save dialog box</strong> don’t forget to ask for <strong>Predicted values (Predicted Values &amp; Residuals).</strong><br />
 </p>
<p><img src="images/ch4/fig_4_1_rslope.png" /></p>
<p><strong>Figure 4.1</strong>. <em>Adding a random slope</em>.<br />
 </p>
<p>This model has 3 fixed effects (intercept, <strong>illiterate_within</strong>, <strong>illiterate_between</strong>), 2 random effects (random intercept variance and random slope variance), plus the residual variance. Let’s start by looking at the plot of the predicted (<em>PRED_</em>) values first (<strong>figure 4.2</strong>).</p>
<p><img src="images/ch4/fig_4_2_pred_rf.png" /></p>
<p><strong>Figure 4.2</strong>. <em>Model 4: Predicted mean number of houses (random intercept and random slope model)</em>.<br />
 </p>
<p>What do you see? The lines look pretty much parallel, but in fact they aren’t (compare <strong>figure 4.2</strong> with <strong>figure 3.3.2</strong>). In <strong>figure 4.2</strong> you see that the last part of the regression equations (slopes), although showing very similar values are in fact different. The slopes for these parishes range from <strong>-.09</strong> to <strong>-.12</strong>, because we allowed the effects of <em>illiterate_within</em> to vary between parishes (that’s what random means in modelling language – we let things vary). They end up not varying that much, but we had to take a look.</p>
<p>Please check the covariance estimates table (<strong>figure 4.3</strong>). We now have 3 estimates there, instead of just 2 as in the previous models. The first 2 are old acquaintances of ours, the last one is a new friend – hello <strong><em>σ</em><sub>slope</sub></strong>, this is us; us, this is <strong><em>σ</em><sub>slope</sub></strong>.</p>
<p>This estimate tells you how much <em>illiterate_within</em> effects vary from parish to parish. The estimate is very close to 0 (<strong>.0035</strong>). Meaning that illiterate effects don’t vary that much (almost nothing) from parish to parish as you’ve seen from the almost parallel lines in <strong>figure 4.2</strong>.  </p>
<p><img src="images/ch4/fig_4_3_random.png" /></p>
<p><strong>Figure 4.3</strong>. Model 4: variance estimates.<br />
 </p>
<div id="comparing-models-the-information-criteria-table" class="section level2">
<h2>4.1 Comparing models: the Information Criteria table</h2>
<p>So, we started with model 3 and then added a random slope to our model (model 4). We have the same fixed predictors in both models (<em>illiterate_between</em> and <em>illiterate_within</em>), but one more random effect in model 4. Can we test whether model 4 is “better” than model 3. YES WE CAN!</p>
<p>Go back to the output of model 3 (where’s that? Nevermind…). The different indices in one <strong>Information Criteria</strong> tables are all similar to one another. These raw values by themselves don’t tell us much, but we can compare Information Criteria values from different models to see if adding/removing fixed and random effects improves model fit. The lower these indices are, the better. That is, a model with lower indices is a better fit to your data than a model with higher indices (better fit equals to explaining better why the dependent variable scores vary from case to case).</p>
<p>Getting back to our models 3 and 4. Let’s look at the first value of Information Criteria tables: <strong>-2 Restricted Log Likelihood</strong> values, aka -2LL, aka <strong>Deviance</strong>. Because models 3 and 4 have the same fixed effects (intercept, <em>illiterate_within</em>, <em>illiterate_between</em>) and differ only on the random part (model 4 has 1 random slope that is absent in model 3) we can use the difference of deviance values to test whether one model fits better than the other.</p>
<p>For model 3, <strong>deviance = 10024.563</strong>; for model 4, <strong>deviance = 10024.482</strong>. If you subtract model 3 deviance from model 4 deviance you get <em>.081</em> (adding parameters is supposed to lower information criteria). This difference has a chi-square distribution. The degrees of freedom (df) of this distribution equal the difference in the number of parameters (1 in this case – the random slope). What this means is that you can use a chi-square test to test whether the goodness of fit of 2 models differ. Repeat after me:<br />
1. compute the deviance difference<br />
2. subtract the number of parameters (to get the df of the chi-square distribution)<br />
3. check a chi-square distribution table, or use this site <a href="https://www.rsquaredcomputing.com/shiny/vistributions/">here</a> (click the chi-square distribution button, click the <em>Find Percentile</em> option, set <em>probability</em> at 0.95 and set degrees of freedom to equal the difference in the number of parameters).</p>
<p>For a chi-square distribution with df = 1, this value is <strong>3.84</strong>. If the deviance difference we found (<strong>.081</strong>) was higher than this, then the 2 models would differ in their fit to the data. It is not, so adding the random slope to model 4 adds pretty much to… nothing! You might have expected this, when we saw that the <strong><em>σ</em><sub>slope</sub> = .0035</strong> (~0) and the lines in the figure were almost parallel.</p>
<p>[<em>Note to future self: write something about comparisons of non-nested models</em>]<br />
 </p>
<div id="reml-and-ml" class="section level3">
<h3>REML and ML</h3>
<p>In the <strong>Linear Mixed Models dialog box</strong> where we specify our models, there’s a button there (<strong>Estimation</strong>) that gives you access to the <strong>Linear Mixed Models: Estimation dialog box</strong>. Using an auto-mechanics analogy, this is what is under the hood. You can choose two estimation options in the <strong>Method section</strong>: REML or ML. REML is the default. I can’t explain how they differ (yet!). The explanation gets a bit technical and I don’t understand it well enough to try and explain it to you in friendly terms.</p>
<p>As far as I have been “told”, REML is better when sample sizes are small (how small is small… well… <em>“Have you noticed how good the weather has been lately?”</em>). ML is better when … (<em>“It feels almost like summer don’t you think?”</em>). When the sample sizes are big, REML and ML are expected to give very similar results. That’s another advantage of BIG data samples – you can pretty much hit buttons at random that results will always look nice.</p>
<p>On a more serious note. The take home message is: 1. If you want to <strong>compare</strong> the fit (compare deviances) of nested models with the <strong>same fixed effects but with different numbers of random effects</strong>, you should <strong>use REML</strong> to estimate both models; 2. if you want to <strong>compare</strong> the fit of nested models with the <strong>same random effects but with different fixed effects</strong>, you should use ML instead. The reason for this is that… (<em>“Do you think it will rain next week?”</em> … got you!).</p>
<p>By the way, <em>nested</em> means that one model is a subset of another. For example, model 1 is nested in model 2 if the parameters in model 1 are a subset of the parameters in model 2. Or in other words, one model is nested in another if you can obtain the first model by constraining some of the parameters of the second model.</p>
<p><a href="https://www.stats.ox.ac.uk/~snijders/mlbook.htm">Snijders &amp; Bosker (2012)</a> provide a set of guiding rules on how to use deviance tests to build your models and decide which variables to keep/drop. The list is long and I’ll eventually summarize it here, but for now I’ll just point the way. Start with fixed effects and interactions that are theoretically meaningful and then add/test one random slope at a time. Don’t go adding a lot of random effects to your models at once (this is one I memorized), it will likely cause SPSS to start throwing errors and warnings at you. There’s a limit to how many random effects you can have- there’s a formula for that somewhere in Snijders &amp; Bosker (2012) (as you probably noticed, everything I don’t know and/or can’t explain – Snijders &amp; Bosker do and can).</p>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
