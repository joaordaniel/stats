# 1. Mixed Models       
Let’s start like this: mixed models also go by the name of multilevel models, hierarchical models, mixed effects models, mixed regression models, random coefficient models. 

Many textbooks abound on this topic. If you dig in a bit you’ll see that some names surface up frequently: Tom Snjiders, Joop Hox, Harvey Goldstein, Stephen Raudenbush to name a few. A lot of the theoretical stuff I present here has been taken from Snijders TAB & Bosker RJ (2012). [Multilevel Analysis: An Introduction to Basic and Advanced Multilevel Modeling](https://www.stats.ox.ac.uk/~snijders/mlbook.htm) - the section on Longitudinal Data / Repeated Measures is an exception. The rest are bits and pieces from here and there. With time I will add references and corresponding links in the text so you can further your explorations of mixed models.  

Another book that I like and that you might want to take a look at is: Heck RH, Thomas SL & Tabata LN (2014). [Multilevel and Longitudinal Modeling with SPSS](https://www.routledge.com/Multilevel-and-Longitudinal-Modeling-with-IBM-SPSS-2nd-Edition/Heck-Thomas-Tabata/p/book/9780415817110). It’s a really nice book to get around mixed models in SPSS. It’s filled with diagrams that will take you by the hand every step of the way.  
&nbsp; 
&nbsp;  

### But why?
Now that the introductions are done, why do we need mixed models? Sometimes we don't, but I’ll give you 3 (not 13) reasons why you should hang around for a little while longer. There are more reasons, but I’m hoping to convince you with just 3. The first two (together with a few more) are detailed in Snijders & Bosker (2012); the last one is my own pragmatic advice.  

**First**: some data sets have a nested/hierarchical/multilevel structure that needs to be accounted for. Failing to do so may lead to erroneous statistical inferences about the relation between independent/predictor variables and the dependent variable. In other words, your beloved low *p* values (on which your career depends on), coming out of an ANOVA, an ANCOVA or a linear regression for instance, maybe be biased and unworthy of your trust.  

ANOVAs, ANCOVAs and linear regression analysis (three different names for pretty much the same thing, so hereafter I’ll just refer to linear regressions) assume your observations (data points) are independent of each other. If your data has a nested structure (say for example, you collected data on 100 children from 10 different schools – children nested in schools), it is likely that two data points (children - lower level unit, aka micro level unit, aka secondary unit) from the same higher level unit (school – aka macro level unit, aka primary unit) are more similar than two data points from different higher level units.   

If they are, then data points (within the same higher level unit) are not independent from each other. That is, they are correlated to some extent (intra class correlation will tell you how much – more on this later). This violates one important assumption of linear regression. The consequence of this non-independence, is that the standard error of your estimates (say, the standard error of the mean test score difference between boys and girls) are more or less biased. This typically means that those precious statistically significant effects, might not be so significant after all (inflation of type I error rate).  
Check these references if this explanation doesn’t satisfy you: [Dorman (2018)](https://www.tandfonline.com/doi/abs/10.1080/01443410801954201) and [Hopkins (1982)](https://journals.sagepub.com/doi/10.3102/00028312019001005).  

**Second**: you have to be careful with ecological fallacies. To avoid them you need to distinguish within-group (level 1) from between-group (level 2) effects, and multilevel models are a great way to do this. Including just one of these effects would only give you part of the story. Take a look at the two images in [Simpson’s paradox Wikipedia page](https://en.wikipedia.org/wiki/Simpson%27s_paradox) to see what I mean. Both images on the right show a negative between-group effect (mean y group scores decrease as x increases) and a positive within-group group effect (within each group, y scores increase as x increases). [Robinson’s (1950)](https://www.jstor.org/stable/2087176?seq=1#page_scan_tab_contents) study on literacy is usually referred as a classic illustration of this fallacy.   
 
**Third**: if the reviewer, supervisor, senior colleague asks/demands, you obey. So let’s do this. Mixed models are hype, and someday you will have someone asking you to reanalyse ALL your data with a mixed model. Sometimes the call will be warranted, other times not so much. Either way you will have to know what this is all about. If you do, you will be able to analyse everything all over again (priceless!!!), or you’ll be able to talk your way out of it (the more jargon you use the more successfully you’ll scare those wannabe reviewers, but be careful, too much bullshit and it starts to stink). So let’s get our hands dirty!
